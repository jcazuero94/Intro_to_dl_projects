{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "778d0397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62fa77a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eafea95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-08 12:38:25.460081: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-08-08 12:38:25.460535: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"model = keras.models.load_model(\\\"../Data/model_face_pair\\\")\";\n",
       "                var nbb_formatted_code = \"model = keras.models.load_model(\\\"../Data/model_face_pair\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"../Data/model_face_pair\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "832c0ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"test_subjects = [l for l in os.listdir(\\\"../Data/test_images/\\\") if l[0] != \\\".\\\"]\";\n",
       "                var nbb_formatted_code = \"test_subjects = [l for l in os.listdir(\\\"../Data/test_images/\\\") if l[0] != \\\".\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_subjects = [l for l in os.listdir(\"../Data/test_images/\") if l[0] != \".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab2c4766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"images_test = {}\\nfor t in test_subjects:\\n    images_test[t] = [\\n        cv2.cvtColor(\\n            cv2.imread(\\\"../Data/test_images/\\\" + t + \\\"/\\\" + im, cv2.IMWRITE_JPEG_QUALITY),\\n            cv2.COLOR_BGR2RGB,\\n        )\\n        for im in os.listdir(\\\"../Data/test_images/\\\" + t)\\n        if im != \\\".DS_Store\\\"\\n    ]\";\n",
       "                var nbb_formatted_code = \"images_test = {}\\nfor t in test_subjects:\\n    images_test[t] = [\\n        cv2.cvtColor(\\n            cv2.imread(\\\"../Data/test_images/\\\" + t + \\\"/\\\" + im, cv2.IMWRITE_JPEG_QUALITY),\\n            cv2.COLOR_BGR2RGB,\\n        )\\n        for im in os.listdir(\\\"../Data/test_images/\\\" + t)\\n        if im != \\\".DS_Store\\\"\\n    ]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_test = {}\n",
    "for t in test_subjects:\n",
    "    images_test[t] = [\n",
    "        cv2.cvtColor(\n",
    "            cv2.imread(\"../Data/test_images/\" + t + \"/\" + im, cv2.IMWRITE_JPEG_QUALITY),\n",
    "            cv2.COLOR_BGR2RGB,\n",
    "        )\n",
    "        for im in os.listdir(\"../Data/test_images/\" + t)\n",
    "        if im != \".DS_Store\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dca85fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"def prepareImg(image):\\n    height = image.shape[0]\\n    width = image.shape[1]\\n    if height > width:\\n        lf = int((height - width) / 2)\\n        rg = height - width - lf\\n        new_img = np.concatenate(\\n            [np.zeros((height, lf, 3)), image, np.zeros((height, rg, 3))], axis=1\\n        )\\n        return cv2.resize(new_img, (250, 250))\\n    elif height < width:\\n        up = int((width - height) / 2)\\n        dn = width - height - up\\n        new_img = np.concatenate(\\n            [np.zeros((up, width, 3)), image, np.zeros((dn, width, 3))], axis=0\\n        )\\n        return cv2.resize(new_img, (250, 250))\\n    return cv2.resize(image, (250, 250))\";\n",
       "                var nbb_formatted_code = \"def prepareImg(image):\\n    height = image.shape[0]\\n    width = image.shape[1]\\n    if height > width:\\n        lf = int((height - width) / 2)\\n        rg = height - width - lf\\n        new_img = np.concatenate(\\n            [np.zeros((height, lf, 3)), image, np.zeros((height, rg, 3))], axis=1\\n        )\\n        return cv2.resize(new_img, (250, 250))\\n    elif height < width:\\n        up = int((width - height) / 2)\\n        dn = width - height - up\\n        new_img = np.concatenate(\\n            [np.zeros((up, width, 3)), image, np.zeros((dn, width, 3))], axis=0\\n        )\\n        return cv2.resize(new_img, (250, 250))\\n    return cv2.resize(image, (250, 250))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prepareImg(image):\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    if height > width:\n",
    "        lf = int((height - width) / 2)\n",
    "        rg = height - width - lf\n",
    "        new_img = np.concatenate(\n",
    "            [np.zeros((height, lf, 3)), image, np.zeros((height, rg, 3))], axis=1\n",
    "        )\n",
    "        return cv2.resize(new_img, (250, 250))\n",
    "    elif height < width:\n",
    "        up = int((width - height) / 2)\n",
    "        dn = width - height - up\n",
    "        new_img = np.concatenate(\n",
    "            [np.zeros((up, width, 3)), image, np.zeros((dn, width, 3))], axis=0\n",
    "        )\n",
    "        return cv2.resize(new_img, (250, 250))\n",
    "    return cv2.resize(image, (250, 250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2b57e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"names_to_test = np.array([])\\ntest_batch = None\\nfor key in images_test.keys():\\n    if test_batch is None:\\n        test_batch = np.concatenate(\\n            [\\n                prepareImg(im).reshape((1, 250, 250, 3)) / 127.5 - 1\\n                for im in images_test[key]\\n            ]\\n        )\\n    else:\\n        test_batch = np.concatenate(\\n            [test_batch]\\n            + [\\n                prepareImg(im).reshape((1, 250, 250, 3)) / 127.5 - 1\\n                for im in images_test[key]\\n            ]\\n        )\\n    names_to_test = np.concatenate(\\n        [names_to_test, np.array([key]).repeat(len(images_test[key]))]\\n    )\";\n",
       "                var nbb_formatted_code = \"names_to_test = np.array([])\\ntest_batch = None\\nfor key in images_test.keys():\\n    if test_batch is None:\\n        test_batch = np.concatenate(\\n            [\\n                prepareImg(im).reshape((1, 250, 250, 3)) / 127.5 - 1\\n                for im in images_test[key]\\n            ]\\n        )\\n    else:\\n        test_batch = np.concatenate(\\n            [test_batch]\\n            + [\\n                prepareImg(im).reshape((1, 250, 250, 3)) / 127.5 - 1\\n                for im in images_test[key]\\n            ]\\n        )\\n    names_to_test = np.concatenate(\\n        [names_to_test, np.array([key]).repeat(len(images_test[key]))]\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names_to_test = np.array([])\n",
    "test_batch = None\n",
    "for key in images_test.keys():\n",
    "    if test_batch is None:\n",
    "        test_batch = np.concatenate(\n",
    "            [\n",
    "                prepareImg(im).reshape((1, 250, 250, 3)) / 127.5 - 1\n",
    "                for im in images_test[key]\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        test_batch = np.concatenate(\n",
    "            [test_batch]\n",
    "            + [\n",
    "                prepareImg(im).reshape((1, 250, 250, 3)) / 127.5 - 1\n",
    "                for im in images_test[key]\n",
    "            ]\n",
    "        )\n",
    "    names_to_test = np.concatenate(\n",
    "        [names_to_test, np.array([key]).repeat(len(images_test[key]))]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1469018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access to the camera was successfully obtained\n",
      "Streaming started\n",
      "Streaming ended\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"video_capture = cv2.VideoCapture(0)\\nif not video_capture.isOpened():\\n    print(\\\"Unable to access the camera\\\")\\nelse:\\n    print(\\\"Access to the camera was successfully obtained\\\")\\n\\nprint(\\\"Streaming started\\\")\\nres = pd.DataFrame()\\nres[\\\"label\\\"] = names_to_test\\n\\nface_cascade = cv2.CascadeClassifier(\\n    cv2.data.haarcascades + \\\"haarcascade_frontalface_default.xml\\\"\\n)\\nwhile True:\\n    # Capture frame-by-frame\\n    ret, frame = video_capture.read()\\n    if not ret:\\n        print(\\\"Can't receive frame (stream end?). Exiting ...\\\")\\n        break\\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\\n    faces = face_cascade.detectMultiScale(\\n        gray,\\n        scaleFactor=1.3,\\n        minNeighbors=5,\\n        minSize=(40, 40),\\n        flags=cv2.CASCADE_SCALE_IMAGE,\\n    )\\n    frame_shape = frame.shape\\n    frame_model = cv2.cvtColor(\\n        frame,\\n        cv2.COLOR_BGR2RGB,\\n    )\\n    for (x, y, w, h) in faces:\\n        y_min = max(y - h, 0)\\n        y_max = min(frame_shape[0], y + 2 * h)\\n        x_min = max(x - w, 0)\\n        x_max = min(frame_shape[1], x + 2 * w)\\n        face_processed = prepareImg(frame_model[y_min:y_max, x_min:x_max, :])\\n        face_processed = np.tile(\\n            face_processed.reshape((1, 250, 250, 3)) / 127.5 - 1,\\n            (len(names_to_test), 1, 1, 1),\\n        )\\n        results_pred = model(np.concatenate([test_batch, face_processed], axis=1))\\n        res[\\\"pred\\\"] = results_pred.numpy().reshape(-1)\\n        best_match = (\\n            res.groupby(\\\"label\\\").max().sort_values(\\\"pred\\\", ascending=False).iloc[0]\\n        )\\n        if best_match[\\\"pred\\\"] > 0.4:\\n            cv2.rectangle(\\n                frame,\\n                (x, y),\\n                (x + w, y + h),\\n                (255, 0, 0),\\n                2,\\n            )\\n            cv2.putText(\\n                img=frame,\\n                text=f'Hello {\\\" \\\".join([str.capitalize(n) for n in best_match.name.split(\\\"_\\\")])} -- {best_match[\\\"pred\\\"]}',\\n                org=(x, y - 10),\\n                fontFace=cv2.FONT_HERSHEY_TRIPLEX,\\n                fontScale=1,\\n                color=(0, 255, 0),\\n                thickness=2,\\n            )\\n\\n    cv2.imshow(\\\"Face detector - to quit press ESC\\\", frame)\\n    # Exit with ESC\\n    key = cv2.waitKey(1)\\n    if key % 256 == 27:  # ESC code\\n        break\\n\\n# When everything done, release the capture\\nvideo_capture.release()\\ncv2.destroyAllWindows()\\ncv2.waitKey(1)\\nprint(\\\"Streaming ended\\\")\";\n",
       "                var nbb_formatted_code = \"video_capture = cv2.VideoCapture(0)\\nif not video_capture.isOpened():\\n    print(\\\"Unable to access the camera\\\")\\nelse:\\n    print(\\\"Access to the camera was successfully obtained\\\")\\n\\nprint(\\\"Streaming started\\\")\\nres = pd.DataFrame()\\nres[\\\"label\\\"] = names_to_test\\n\\nface_cascade = cv2.CascadeClassifier(\\n    cv2.data.haarcascades + \\\"haarcascade_frontalface_default.xml\\\"\\n)\\nwhile True:\\n    # Capture frame-by-frame\\n    ret, frame = video_capture.read()\\n    if not ret:\\n        print(\\\"Can't receive frame (stream end?). Exiting ...\\\")\\n        break\\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\\n    faces = face_cascade.detectMultiScale(\\n        gray,\\n        scaleFactor=1.3,\\n        minNeighbors=5,\\n        minSize=(40, 40),\\n        flags=cv2.CASCADE_SCALE_IMAGE,\\n    )\\n    frame_shape = frame.shape\\n    frame_model = cv2.cvtColor(\\n        frame,\\n        cv2.COLOR_BGR2RGB,\\n    )\\n    for (x, y, w, h) in faces:\\n        y_min = max(y - h, 0)\\n        y_max = min(frame_shape[0], y + 2 * h)\\n        x_min = max(x - w, 0)\\n        x_max = min(frame_shape[1], x + 2 * w)\\n        face_processed = prepareImg(frame_model[y_min:y_max, x_min:x_max, :])\\n        face_processed = np.tile(\\n            face_processed.reshape((1, 250, 250, 3)) / 127.5 - 1,\\n            (len(names_to_test), 1, 1, 1),\\n        )\\n        results_pred = model(np.concatenate([test_batch, face_processed], axis=1))\\n        res[\\\"pred\\\"] = results_pred.numpy().reshape(-1)\\n        best_match = (\\n            res.groupby(\\\"label\\\").max().sort_values(\\\"pred\\\", ascending=False).iloc[0]\\n        )\\n        if best_match[\\\"pred\\\"] > 0.4:\\n            cv2.rectangle(\\n                frame,\\n                (x, y),\\n                (x + w, y + h),\\n                (255, 0, 0),\\n                2,\\n            )\\n            cv2.putText(\\n                img=frame,\\n                text=f'Hello {\\\" \\\".join([str.capitalize(n) for n in best_match.name.split(\\\"_\\\")])} -- {best_match[\\\"pred\\\"]}',\\n                org=(x, y - 10),\\n                fontFace=cv2.FONT_HERSHEY_TRIPLEX,\\n                fontScale=1,\\n                color=(0, 255, 0),\\n                thickness=2,\\n            )\\n\\n    cv2.imshow(\\\"Face detector - to quit press ESC\\\", frame)\\n    # Exit with ESC\\n    key = cv2.waitKey(1)\\n    if key % 256 == 27:  # ESC code\\n        break\\n\\n# When everything done, release the capture\\nvideo_capture.release()\\ncv2.destroyAllWindows()\\ncv2.waitKey(1)\\nprint(\\\"Streaming ended\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "if not video_capture.isOpened():\n",
    "    print(\"Unable to access the camera\")\n",
    "else:\n",
    "    print(\"Access to the camera was successfully obtained\")\n",
    "\n",
    "print(\"Streaming started\")\n",
    "res = pd.DataFrame()\n",
    "res[\"label\"] = names_to_test\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    ")\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=5,\n",
    "        minSize=(40, 40),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE,\n",
    "    )\n",
    "    frame_shape = frame.shape\n",
    "    frame_model = cv2.cvtColor(\n",
    "        frame,\n",
    "        cv2.COLOR_BGR2RGB,\n",
    "    )\n",
    "    for (x, y, w, h) in faces:\n",
    "        y_min = max(y - h, 0)\n",
    "        y_max = min(frame_shape[0], y + 2 * h)\n",
    "        x_min = max(x - w, 0)\n",
    "        x_max = min(frame_shape[1], x + 2 * w)\n",
    "        face_processed = prepareImg(frame_model[y_min:y_max, x_min:x_max, :])\n",
    "        face_processed = np.tile(\n",
    "            face_processed.reshape((1, 250, 250, 3)) / 127.5 - 1,\n",
    "            (len(names_to_test), 1, 1, 1),\n",
    "        )\n",
    "        results_pred = model(np.concatenate([test_batch, face_processed], axis=1))\n",
    "        res[\"pred\"] = results_pred.numpy().reshape(-1)\n",
    "        best_match = (\n",
    "            res.groupby(\"label\").max().sort_values(\"pred\", ascending=False).iloc[0]\n",
    "        )\n",
    "        if best_match[\"pred\"] > 0.4:\n",
    "            cv2.rectangle(\n",
    "                frame,\n",
    "                (x, y),\n",
    "                (x + w, y + h),\n",
    "                (255, 0, 0),\n",
    "                2,\n",
    "            )\n",
    "            cv2.putText(\n",
    "                img=frame,\n",
    "                text=f'Hello {\" \".join([str.capitalize(n) for n in best_match.name.split(\"_\")])} -- {best_match[\"pred\"]}',\n",
    "                org=(x, y - 10),\n",
    "                fontFace=cv2.FONT_HERSHEY_TRIPLEX,\n",
    "                fontScale=1,\n",
    "                color=(0, 255, 0),\n",
    "                thickness=2,\n",
    "            )\n",
    "\n",
    "    cv2.imshow(\"Face detector - to quit press ESC\", frame)\n",
    "    # Exit with ESC\n",
    "    key = cv2.waitKey(1)\n",
    "    if key % 256 == 27:  # ESC code\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "print(\"Streaming ended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf12dfbd",
   "metadata": {},
   "source": [
    "The video capture code is based on\n",
    "\n",
    "https://towardsdatascience.com/how-to-create-real-time-face-detector-ff0e1f81925f\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1023bf16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
